{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import spacy\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "# !python3 -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 300)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Lexique383.xlsb\", engine='pyxlsb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_ortho</th>\n",
       "      <th>2_phon</th>\n",
       "      <th>3_lemme</th>\n",
       "      <th>4_cgram</th>\n",
       "      <th>5_genre</th>\n",
       "      <th>6_nombre</th>\n",
       "      <th>7_freqlemfilms2</th>\n",
       "      <th>8_freqlemlivres</th>\n",
       "      <th>9_freqfilms2</th>\n",
       "      <th>10_freqlivres</th>\n",
       "      <th>...</th>\n",
       "      <th>26_orthrenv</th>\n",
       "      <th>27_phonrenv</th>\n",
       "      <th>28_orthosyll</th>\n",
       "      <th>29_cgramortho</th>\n",
       "      <th>30_deflem</th>\n",
       "      <th>31_defobs</th>\n",
       "      <th>32_old20</th>\n",
       "      <th>33_pld20</th>\n",
       "      <th>34_morphoder</th>\n",
       "      <th>35_nbmorph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.36</td>\n",
       "      <td>58.65</td>\n",
       "      <td>81.36</td>\n",
       "      <td>58.65</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>avoir</td>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18559.22</td>\n",
       "      <td>12800.81</td>\n",
       "      <td>6350.91</td>\n",
       "      <td>2926.69</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>avoir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>avoir</td>\n",
       "      <td>VER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13572.40</td>\n",
       "      <td>6426.49</td>\n",
       "      <td>5498.34</td>\n",
       "      <td>1669.39</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "      <td>93.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>avoir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a capella</td>\n",
       "      <td>akapEla</td>\n",
       "      <td>a capella</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>allepac a</td>\n",
       "      <td>alEpaka</td>\n",
       "      <td>a ca-pel-la</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.85</td>\n",
       "      <td>a-capella</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>akapEla</td>\n",
       "      <td>a cappella</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>alleppac a</td>\n",
       "      <td>alEpaka</td>\n",
       "      <td>a cap-pel-la</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.85</td>\n",
       "      <td>a-cappella</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1_ortho   2_phon     3_lemme 4_cgram 5_genre 6_nombre  7_freqlemfilms2  \\\n",
       "0           a        a           a     NOM       m      NaN            81.36   \n",
       "1           a        a       avoir     AUX     NaN      NaN         18559.22   \n",
       "2           a        a       avoir     VER     NaN      NaN         13572.40   \n",
       "3   a capella  akapEla   a capella     ADV     NaN      NaN             0.04   \n",
       "4  a cappella  akapEla  a cappella     ADV     NaN      NaN             0.04   \n",
       "\n",
       "   8_freqlemlivres  9_freqfilms2  10_freqlivres  ... 26_orthrenv  27_phonrenv  \\\n",
       "0            58.65         81.36          58.65  ...           a            a   \n",
       "1         12800.81       6350.91        2926.69  ...           a            a   \n",
       "2          6426.49       5498.34        1669.39  ...           a            a   \n",
       "3             0.07          0.04           0.07  ...   allepac a      alEpaka   \n",
       "4             0.07          0.04           0.07  ...  alleppac a      alEpaka   \n",
       "\n",
       "   28_orthosyll  29_cgramortho  30_deflem  31_defobs 32_old20 33_pld20  \\\n",
       "0             a    NOM,AUX,VER        NaN        NaN     1.00     1.00   \n",
       "1             a    NOM,AUX,VER        NaN        NaN     1.00     1.00   \n",
       "2             a    NOM,AUX,VER       93.0       16.0     1.00     1.00   \n",
       "3   a ca-pel-la            ADV        NaN        NaN     3.85     2.85   \n",
       "4  a cap-pel-la            ADV        NaN        NaN     4.60     2.85   \n",
       "\n",
       "   34_morphoder  35_nbmorph  \n",
       "0             a           1  \n",
       "1         avoir           1  \n",
       "2         avoir           1  \n",
       "3     a-capella           2  \n",
       "4    a-cappella           2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove prepositions, articles, pronouns, conjonctions ...\n",
    "word_df = df.loc[-df[\"4_cgram\"].str[:3].isin([\"PRO\", \"PRE\", \"ART\", \"LIA\", \"ONO\", \"CON\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "BDD current size: 0\n",
      "30000\n",
      "BDD current size: 10898\n",
      "60000\n",
      "BDD current size: 17291\n",
      "90000\n",
      "BDD current size: 21620\n",
      "120000\n",
      "BDD current size: 24786\n",
      "150000\n",
      "BDD current size: 27193\n",
      "180000\n",
      "BDD current size: 29033\n",
      "210000\n",
      "BDD current size: 30492\n",
      "240000\n",
      "BDD current size: 31755\n",
      "270000\n",
      "BDD current size: 32736\n",
      "300000\n",
      "BDD current size: 33549\n",
      "330000\n",
      "BDD current size: 34235\n",
      "360000\n",
      "BDD current size: 34888\n",
      "390000\n",
      "BDD current size: 35467\n",
      "420000\n",
      "BDD current size: 35988\n",
      "450000\n",
      "BDD current size: 36453\n",
      "480000\n",
      "BDD current size: 36886\n"
     ]
    }
   ],
   "source": [
    "BDD = {}\n",
    "#iterate our word embeddings list\n",
    "for i, key in enumerate(nlp.vocab.vectors.keys()):\n",
    "    #retrieve word\n",
    "    w = nlp.vocab.strings[key]\n",
    "    if i % 30000 == 0:\n",
    "        print(i)\n",
    "        print(f\"BDD current size: {len(BDD.keys())}\")\n",
    "        \n",
    "    #if the word is not in the french dictionnary of lemmas\n",
    "    if w not in word_df[\"3_lemme\"].unique():\n",
    "        continue\n",
    "        \n",
    "    #else, add it to the database\n",
    "    vector = nlp.vocab.vectors.data[i]\n",
    "    BDD[w] = vector\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les noms propres ne sont pas inclus. dict(nlp(word).to_json())[\"tokens\"][0][\"pos\"] == \"PROPN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word_database.pkl\", \"wb\") as f:\n",
    "    pickle.dump(BDD, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
